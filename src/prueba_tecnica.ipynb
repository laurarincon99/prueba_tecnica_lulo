{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba Técnica\n",
    "\n",
    "### Laura Camila Rincón Manrique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install requests\n",
    "#!pip install json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_data_dates(url,date):\n",
    "    url = f\"{url}{date}\"\n",
    "    api_response = requests.get(url)\n",
    "    if api_response.status_code == 200:\n",
    "        return api_response.json()\n",
    "    else:\n",
    "        print(f\"Error al obtener los datos para la fecha {date}, Error API: {api_response.status_code}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Verify_file_exist(path_file):   \n",
    "    if os.path.exists(path_file):\n",
    "        os.remove(path_file)\n",
    "        print(f\"The file {path_file} was delete.\")\n",
    "    else:\n",
    "        print(f\"The file {path_file} doesn't exist and It is goint to create.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save_json(data,path_file):\n",
    "    with open(path_file, 'w') as archivo:\n",
    "        json.dump(data, archivo, indent=4)\n",
    "    print(f\"Datos almacenados en {path_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the data to: 2024-01-01\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-01.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-01.json\n",
      "Getting the data to: 2024-01-02\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-02.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-02.json\n",
      "Getting the data to: 2024-01-03\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-03.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-03.json\n",
      "Getting the data to: 2024-01-04\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-04.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-04.json\n",
      "Getting the data to: 2024-01-05\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-05.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-05.json\n",
      "Getting the data to: 2024-01-06\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-06.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-06.json\n",
      "Getting the data to: 2024-01-07\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-07.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-07.json\n",
      "Getting the data to: 2024-01-08\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-08.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-08.json\n",
      "Getting the data to: 2024-01-09\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-09.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-09.json\n",
      "Getting the data to: 2024-01-10\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-10.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-10.json\n",
      "Getting the data to: 2024-01-11\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-11.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-11.json\n",
      "Getting the data to: 2024-01-12\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-12.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-12.json\n",
      "Getting the data to: 2024-01-13\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-13.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-13.json\n",
      "Getting the data to: 2024-01-14\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-14.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-14.json\n",
      "Getting the data to: 2024-01-15\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-15.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-15.json\n",
      "Getting the data to: 2024-01-16\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-16.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-16.json\n",
      "Getting the data to: 2024-01-17\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-17.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-17.json\n",
      "Getting the data to: 2024-01-18\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-18.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-18.json\n",
      "Getting the data to: 2024-01-19\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-19.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-19.json\n",
      "Getting the data to: 2024-01-20\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-20.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-20.json\n",
      "Getting the data to: 2024-01-21\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-21.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-21.json\n",
      "Getting the data to: 2024-01-22\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-22.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-22.json\n",
      "Getting the data to: 2024-01-23\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-23.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-23.json\n",
      "Getting the data to: 2024-01-24\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-24.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-24.json\n",
      "Getting the data to: 2024-01-25\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-25.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-25.json\n",
      "Getting the data to: 2024-01-26\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-26.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-26.json\n",
      "Getting the data to: 2024-01-27\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-27.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-27.json\n",
      "Getting the data to: 2024-01-28\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-28.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-28.json\n",
      "Getting the data to: 2024-01-29\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-29.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-29.json\n",
      "Getting the data to: 2024-01-30\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-30.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-30.json\n",
      "Getting the data to: 2024-01-31\n",
      "The file C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-31.json was delete.\n",
      "Datos almacenados en C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_2024-01-31.json\n"
     ]
    }
   ],
   "source": [
    "#Data Range\n",
    "initial_date = datetime(2024, 1, 1)\n",
    "end_date = datetime(2024, 1, 31) \n",
    "actual_date = initial_date\n",
    "url = \"http://api.tvmaze.com/schedule/web?date=\"\n",
    "archivo = 'ejemplo.json'\n",
    "\n",
    "\n",
    "list_data = []\n",
    "\n",
    "while actual_date <= end_date:\n",
    "    date_str = actual_date.strftime('%Y-%m-%d')  #YYYY-MM-DD\n",
    "    path_file = f'C:/Users/camil/Desktop/prueba_tecnica_lulo/json/data_{date_str}.json'\n",
    "    print(f\"Getting the data to: {date_str}\")\n",
    "\n",
    "    data = Get_data_dates(url,date_str)\n",
    "\n",
    "    if data:\n",
    "        list_data.extend(data)\n",
    "        Verify_file_exist(path_file)\n",
    "        Save_json(data,path_file)\n",
    "\n",
    "    actual_date += timedelta(days=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes_df = pd.DataFrame(columns=[\"id_index\",\"id\",\"url\",\"name\",\"season\",\"number\",\"type\",\"airdate\",\"airtime\",\n",
    "                                                 \"airstamp\",\"runtime\",\"rating_average\",\"image\",\"summary\"])\n",
    "links_episodes_df = pd.DataFrame(columns=[\"id_index\",\"id_episodes\",\"self_href\",\"show_href\",\"show_name\"])\n",
    "embedded_df = pd.DataFrame(columns=[\"id_index\",\"id_episodes\",\"id\",\"url\",\"name\",\"type\",\"language\",\"status\",\"runtime\",\n",
    "                                    \"averageRuntime\",\"premiered\",\"ended\",\"officialSite\",\"schedule_time\",\"rating_average\",\"weight\",\"network\",\"dvdCountry\",\"summary\",\"updated\"])\n",
    "genres_df = pd.DataFrame(columns=[\"id_index\",\"id_episodes\",\"genres\"])\n",
    "days_df = pd.DataFrame(columns=[\"id_index\",\"id_episodes\",\"days\"])\n",
    "webChannel_df = pd.DataFrame(columns=[\"id_index\",\"id_episodes\",\"id\",\"name\",\"country_name\",\"country_code\",\n",
    "                                      \"country_timezone\",\"officialSite\"])\n",
    "image_df = pd.DataFrame(columns=[\"id_index\",\"id_episodes\",\"medium\",\"original\"])\n",
    "externals_df = pd.DataFrame(columns=[\"id_index\",\"id_episodes\",\"tvrage\",\"thetvdb\",\"imdb\"])\n",
    "links_show_df = pd.DataFrame(columns=[\"id_index\",\"id_episodes\",\"self_href\",\"previousepisode_href\",\"previousepisode_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_index</th>\n",
       "      <th>id_episodes</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id_index, id_episodes, genres]\n",
       "Index: []"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the links dataframe\n",
    "def Links_dataframe(dic_data,id,row):\n",
    "    links_episodes_df.loc[row,'id_episodes'] = id\n",
    "    links_episodes_df.loc[row,'id_index'] = row + 1\n",
    "    links_episodes_df.loc[row,'self_href'] = dic_data.get('self',{}).get('href')\n",
    "    links_episodes_df.loc[row,'show_href'] = dic_data.get('show',{}).get('href')\n",
    "    links_episodes_df.loc[row,'show_name'] = dic_data.get('show',{}).get('name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the links_show dataframe\n",
    "def Links_show_dataframe(dic_data,id,row):\n",
    "    links_show_df.loc[row,'id_episodes'] = id\n",
    "    links_show_df.loc[row,'id_index'] = row + 1\n",
    "    links_show_df.loc[row,'self_href'] = dic_data.get('self',{}).get('href')\n",
    "    links_show_df.loc[row,'previousepisode_href'] = dic_data.get('previousepisode',{}).get('href')\n",
    "    links_show_df.loc[row,'previousepisode_name'] = dic_data.get('previousepisode',{}).get('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the simple dict to dataframe Use in image and externals\n",
    "def dict_to_dataframe(dic_data,id,df):\n",
    "    index_df = len(df)\n",
    "    for k in dic_data.keys():\n",
    "        df.loc[index_df,'id_index'] = index_df + 1\n",
    "        df.loc[index_df,'id_episodes'] = id\n",
    "        df.loc[index_df,k] = dic_data.get(k)\n",
    "        #index_df += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the simple list to dataframe\n",
    "def list_to_dataframe(list_data,df,column_name,id):\n",
    "    index_df = len(df)\n",
    "    for i in list_data:\n",
    "        df.loc[index_df,'id_index'] = index_df + 1\n",
    "        df.loc[index_df,'id_episodes'] = id\n",
    "        df.loc[index_df,column_name] = i\n",
    "        index_df += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the genres dataframe\n",
    "def Genres_dataframe(list_data,id):\n",
    "    index_df = len(genres_df)\n",
    "    for i in list_data:\n",
    "        genres_df.loc[index_df,'id_index'] = index_df + 1\n",
    "        genres_df.loc[index_df,'id_episodes'] = id\n",
    "        genres_df.loc[index_df,'genres'] = i\n",
    "        index_df += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the days dataframe\n",
    "def Days_schedule_dataframe(list_data,id):\n",
    "    index_df = len(genres_df)\n",
    "    for i in list_data:\n",
    "        days_df.loc[index_df,'id_index'] = index_df + 1\n",
    "        days_df.loc[index_df,'id_episodes'] = id\n",
    "        days_df.loc[index_df,'days'] = i\n",
    "        index_df += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the WebChannel dataframe\n",
    "def WebChannel_dataframe(dic_data,id,row):\n",
    "    dic_keys = dic_data.keys()\n",
    "    webChannel_df.loc[row,'id_episodes'] = id\n",
    "    webChannel_df.loc[row,'id_index'] = row + 1\n",
    "    for k in dic_keys:\n",
    "        #print(k)\n",
    "        #print(isinstance(dic_data.get(k), dict))\n",
    "        if not(isinstance(dic_data.get(k), dict)):\n",
    "            #print(dic_data.get(k))\n",
    "            webChannel_df.loc[row,k] = dic_data.get(k)\n",
    "        elif k == \"country\":\n",
    "            webChannel_df.loc[row,'country_name'] = dic_data.get(k,{}).get('name')\n",
    "            webChannel_df.loc[row,'country_code'] = dic_data.get(k,{}).get('code')\n",
    "            webChannel_df.loc[row,'country_timezone'] = dic_data.get(k,{}).get('timezone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Embedded dataframe\n",
    "def Embedded_dataframe(dic_data,id,row):\n",
    "    dic_keys = dic_data.keys()\n",
    "    embedded_df.loc[row,'id_episodes'] = id\n",
    "    embedded_df.loc[row,'id_index'] = row + 1\n",
    "    for k in dic_keys:\n",
    "        #print(k)\n",
    "        #print(isinstance(dic_data.get(k), dict))\n",
    "        if not(isinstance(dic_data.get(k), dict)) and not(isinstance(dic_data.get(k), list)):\n",
    "            #print(dic_data.get(k))\n",
    "            embedded_df.loc[row,k] = dic_data.get(k)\n",
    "        elif k == \"genres\":\n",
    "            list_to_dataframe(dic_data.get(k),genres_df,'genres',id)\n",
    "            #Genres_dataframe(dic_data.get(k),id)\n",
    "        elif k == \"schedule\":\n",
    "            embedded_df.loc[row,'schedule_time'] = dic_data.get(k,{}).get('time')\n",
    "            list_to_dataframe(dic_data.get(k,{}).get('days'),days_df,'days',id)\n",
    "            #Days_schedule_dataframe(dic_data.get(k,{}).get('days'),id)\n",
    "        elif k == \"rating\":\n",
    "            embedded_df.loc[row,'rating_average'] = dic_data.get(k,{}).get('average')\n",
    "        elif k == \"webChannel\":\n",
    "            WebChannel_dataframe(dic_data.get(k,),id,row)\n",
    "        elif k == \"externals\":\n",
    "            dict_to_dataframe(dic_data.get(k,),id,externals_df)\n",
    "        elif k == \"image\":\n",
    "            dict_to_dataframe(dic_data.get(k,),id,image_df)\n",
    "        elif k == \"_links\":\n",
    "            Links_show_dataframe(dic_data.get(k,),id,row)\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_dataframe(dic_data,row):\n",
    "    dic_keys = dic_data.keys()\n",
    "    episodes_df.loc[row,\"id_index\"] = row + 1\n",
    "    for k in dic_keys:\n",
    "        #print(k)\n",
    "        #print(isinstance(dic_data.get(k), dict))\n",
    "        if not(isinstance(dic_data.get(k), dict)):\n",
    "            #print(dic_data.get(k))\n",
    "            episodes_df.loc[row,k] = dic_data.get(k)\n",
    "        elif k == \"rating\":\n",
    "            episodes_df.loc[row,'rating_average'] = dic_data.get(k,{}).get('average')\n",
    "        elif k == \"_links\":\n",
    "            Links_dataframe(dic_data.get(k),dic_data.get('id'),row)\n",
    "        elif k == \"_embedded\":\n",
    "            Embedded_dataframe(dic_data.get(k,{}).get(\"show\",{}),dic_data.get('id'),row)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "Create_dataframe(list_data[0],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_index</th>\n",
       "      <th>id_episodes</th>\n",
       "      <th>self_href</th>\n",
       "      <th>previousepisode_href</th>\n",
       "      <th>previousepisode_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2730586</td>\n",
       "      <td>https://api.tvmaze.com/shows/51908</td>\n",
       "      <td>https://api.tvmaze.com/episodes/2730595</td>\n",
       "      <td>Серия 10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_index id_episodes                           self_href  \\\n",
       "0        1     2730586  https://api.tvmaze.com/shows/51908   \n",
       "\n",
       "                      previousepisode_href previousepisode_name  \n",
       "0  https://api.tvmaze.com/episodes/2730595             Серия 10  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_show_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
